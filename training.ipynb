{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training driving model with behavioral cloning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook, we will train a NN using samples obtained from Udacity Simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we create a dataset from different runs (folders) to train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/josealb/HDD_1/Datasets/Self_driving/Simulator_Data/Merge/ND_Sample\n",
      "/media/josealb/HDD_1/Datasets/Self_driving/Simulator_Data/Merge/ND_Sample/IMG\n",
      "/media/josealb/HDD_1/Datasets/Self_driving/Simulator_Data/Merge/right_lane_2\n",
      "/media/josealb/HDD_1/Datasets/Self_driving/Simulator_Data/Merge/right_lane_2/IMG\n",
      "/media/josealb/HDD_1/Datasets/Self_driving/Simulator_Data/Merge/Track1_2\n",
      "/media/josealb/HDD_1/Datasets/Self_driving/Simulator_Data/Merge/Track1_2/IMG\n",
      "/media/josealb/HDD_1/Datasets/Self_driving/Simulator_Data/Merge/Track2_2\n",
      "/media/josealb/HDD_1/Datasets/Self_driving/Simulator_Data/Merge/Track2_2/IMG\n",
      "/media/josealb/HDD_1/Datasets/Self_driving/Simulator_Data/Merge/Track_1\n",
      "/media/josealb/HDD_1/Datasets/Self_driving/Simulator_Data/Merge/Track_1/IMG\n",
      "/media/josealb/HDD_1/Datasets/Self_driving/Simulator_Data/Merge/Track_2\n",
      "/media/josealb/HDD_1/Datasets/Self_driving/Simulator_Data/Merge/Track_2/IMG\n",
      "/media/josealb/HDD_1/Datasets/Self_driving/Simulator_Data/Merge/track_2_right_lane\n",
      "/media/josealb/HDD_1/Datasets/Self_driving/Simulator_Data/Merge/track_2_right_lane/IMG\n",
      "/media/josealb/HDD_1/Datasets/Self_driving/Simulator_Data/Merge/ND_Sample/driving_log.csv\n",
      "/media/josealb/HDD_1/Datasets/Self_driving/Simulator_Data/Merge/right_lane_2/driving_log.csv\n",
      "/media/josealb/HDD_1/Datasets/Self_driving/Simulator_Data/Merge/Track1_2/driving_log.csv\n",
      "/media/josealb/HDD_1/Datasets/Self_driving/Simulator_Data/Merge/Track2_2/driving_log.csv\n",
      "/media/josealb/HDD_1/Datasets/Self_driving/Simulator_Data/Merge/Track_1/driving_log.csv\n",
      "/media/josealb/HDD_1/Datasets/Self_driving/Simulator_Data/Merge/Track_2/driving_log.csv\n",
      "/media/josealb/HDD_1/Datasets/Self_driving/Simulator_Data/Merge/track_2_right_lane/driving_log.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from shutil import copyfile\n",
    "import pandas\n",
    "import fileinput\n",
    "#Create directory with all data merged into one\n",
    "datafolder = '/media/josealb/HDD_1/Datasets/Self_driving/Simulator_Data/Merge'\n",
    "outputfolder = '/media/josealb/HDD_1/Datasets/Self_driving/Simulator_Data/All_tracks'\n",
    "subdirs = [x[0] for x in os.walk(datafolder)] \n",
    "subdirs.pop(0)\n",
    "subdirs\n",
    "fileList=[]\n",
    "os.mkdir(outputfolder)\n",
    "os.mkdir(outputfolder+'/IMG') \n",
    "\n",
    "\n",
    "for dir in subdirs:\n",
    "    if \"IMG\" in dir:\n",
    "        print(dir)\n",
    "        files= [f for f in listdir(dir) if isfile(join(dir, f))]\n",
    "        for file in files:\n",
    "            copyfile(dir+'/'+file,outputfolder+'/IMG/'+file)\n",
    "    if \"IMG\" not in dir:\n",
    "        print(dir)\n",
    "        fileList.append(dir+'/driving_log.csv')\n",
    "        \n",
    "dfList=[]\n",
    "for filename in fileList:\n",
    "    print(filename)\n",
    "    df=pandas.read_csv(filename,header=None)\n",
    "    dfList.append(df)\n",
    "concatDf=pandas.concat(dfList,axis=0)\n",
    "concatDf.to_csv(outputfolder+'/driving_log.csv',index=None,header=None)\n",
    "\n",
    "with fileinput.FileInput(outputfolder+'/driving_log.csv', inplace=True, backup='.bak') as file:\n",
    "    for line in file:\n",
    "        print(line.replace('\\\\', '/'), end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Now, we train the network on the created dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "92490/92490 [==============================] - 144s - loss: 0.1320 - val_loss: 0.0882\n",
      "Epoch 2/25\n",
      "92490/92490 [==============================] - 136s - loss: 0.0623 - val_loss: 0.0611\n",
      "Epoch 3/25\n",
      "92490/92490 [==============================] - 136s - loss: 0.0565 - val_loss: 0.0551\n",
      "Epoch 4/25\n",
      "92490/92490 [==============================] - 135s - loss: 0.0531 - val_loss: 0.0550\n",
      "Epoch 5/25\n",
      "92490/92490 [==============================] - 132s - loss: 0.0502 - val_loss: 0.0482\n",
      "Epoch 6/25\n",
      "92490/92490 [==============================] - 134s - loss: 0.0477 - val_loss: 0.0462\n",
      "Epoch 7/25\n",
      "92490/92490 [==============================] - 133s - loss: 0.0455 - val_loss: 0.0425\n",
      "Epoch 8/25\n",
      "92490/92490 [==============================] - 133s - loss: 0.0440 - val_loss: 0.0454\n",
      "Epoch 9/25\n",
      "92490/92490 [==============================] - 132s - loss: 0.0428 - val_loss: 0.0477\n",
      "Epoch 10/25\n",
      "92490/92490 [==============================] - 132s - loss: 0.0416 - val_loss: 0.0450\n",
      "Epoch 11/25\n",
      "92490/92490 [==============================] - 132s - loss: 0.0406 - val_loss: 0.0433\n",
      "Epoch 12/25\n",
      "92490/92490 [==============================] - 133s - loss: 0.0394 - val_loss: 0.0395\n",
      "Epoch 13/25\n",
      "92490/92490 [==============================] - 132s - loss: 0.0383 - val_loss: 0.0376\n",
      "Epoch 14/25\n",
      "92490/92490 [==============================] - 132s - loss: 0.0370 - val_loss: 0.0388\n",
      "Epoch 15/25\n",
      "92490/92490 [==============================] - 133s - loss: 0.0358 - val_loss: 0.0382\n",
      "Epoch 16/25\n",
      "92490/92490 [==============================] - 132s - loss: 0.0343 - val_loss: 0.0377\n",
      "Epoch 17/25\n",
      "92490/92490 [==============================] - 133s - loss: 0.0325 - val_loss: 0.0356\n",
      "Epoch 18/25\n",
      "92490/92490 [==============================] - 133s - loss: 0.0312 - val_loss: 0.0343\n",
      "Epoch 19/25\n",
      "92490/92490 [==============================] - 131s - loss: 0.0299 - val_loss: 0.0325\n",
      "Epoch 20/25\n",
      "92490/92490 [==============================] - 131s - loss: 0.0290 - val_loss: 0.0334\n",
      "Epoch 21/25\n",
      "92490/92490 [==============================] - 131s - loss: 0.0277 - val_loss: 0.0365\n",
      "Epoch 22/25\n",
      "92490/92490 [==============================] - 133s - loss: 0.0265 - val_loss: 0.0311\n",
      "Epoch 23/25\n",
      "92490/92490 [==============================] - 133s - loss: 0.0259 - val_loss: 0.0291\n",
      "Epoch 24/25\n",
      "92490/92490 [==============================] - 134s - loss: 0.0251 - val_loss: 0.0291\n",
      "Epoch 25/25\n",
      "92490/92490 [==============================] - 134s - loss: 0.0243 - val_loss: 0.0288\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import pdb\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Lambda\n",
    "from keras.layers import Cropping2D\n",
    "from keras.layers.convolutional import Convolution2D, Conv2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import optimizers\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "datafolder = '/media/josealb/HDD_1/Datasets/Self_driving/Simulator_Data/All_tracks_20_09_2017/'\n",
    "#datafolder = '/media/josealb/HDD_1/Datasets/Self_driving/Simulator_Data/track_2_right_lane/'\n",
    "\n",
    "samples = []\n",
    "\n",
    "with open(datafolder+'driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "                   \n",
    "        \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "\n",
    "\n",
    "def random_augmentation(image,steering_angle):\n",
    "    if rand(0,1)>0:\n",
    "        image=np.fliplr(image)\n",
    "        angle=-angle\n",
    "    return image, steering_angle\n",
    "        \n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                name_center = datafolder+'IMG/'+batch_sample[0].split('/')[-1]\n",
    "                name_left = datafolder+'IMG/'+batch_sample[1].split('/')[-1]\n",
    "                name_right = datafolder+'IMG/'+batch_sample[2].split('/')[-1]\n",
    "\n",
    "                original_center = cv2.imread(name_center)\n",
    "                center_image = cv2.cvtColor(original_center, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                original_left = cv2.imread(name_left)\n",
    "                left_image=cv2.cvtColor(original_left, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                original_right = cv2.imread(name_right)\n",
    "                right_image=cv2.cvtColor(original_right, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                if center_image is None: #Enter debugger if something went wrong loading the image\n",
    "                    pdb.set_trace()\n",
    "\n",
    "                center_angle = float(batch_sample[3])\n",
    "                center_angle = center_angle#*turn_aggresiveness #Makes Neural network turn more aggresively\n",
    "                correction = 0.2\n",
    "                \n",
    "                left_angle = center_angle + correction\n",
    "                right_angle= center_angle - correction\n",
    "                \n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "                images.append(left_image)\n",
    "                angles.append(left_angle)\n",
    "                images.append(right_image)\n",
    "                angles.append(right_angle)     \n",
    "                   \n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size=128)\n",
    "validation_generator = generator(validation_samples, batch_size=128)\n",
    "\n",
    "#ch, row, col = 3, 80, 320  # Trimmed image format\n",
    "ch, row, col = 3, 160, 320  # UnTrimmed image format\n",
    "\n",
    "model = Sequential()\n",
    "# Preprocess incoming data, centered around zero with small standard deviation \n",
    "\n",
    "model.add(Cropping2D(cropping=((50,20), (0,0)), input_shape=(row,col,ch)))\n",
    "model.add(Lambda(lambda x: x/127.5 - 1.))#,\n",
    "       # input_shape=(row, col, ch),\n",
    "        #output_shape=(row, col, ch)))\n",
    "\n",
    "#model.add(Convolution2D(24,9,9, activation=\"relu\"))#experimental layer with larger filter size for the first activations      \n",
    "model.add(Conv2D(34,5,5,subsample=(2,2), activation=\"elu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(46,5,5,subsample=(2,2), activation=\"elu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(58,5,5,subsample=(2,2), activation=\"elu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(74,3,3, activation=\"elu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(74,3,3, activation=\"elu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1164))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(200))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(100))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(20))\n",
    "model.add(BatchNormalization())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "checkpoint = ModelCheckpoint('model-{epoch:03d}-{val_loss:03f}.h5',\n",
    "                            monitor='val_loss',\n",
    "                            verbose=0,\n",
    "                            save_best_only=True,\n",
    "                            mode = 'auto')\n",
    "\n",
    "model.fit_generator(train_generator, samples_per_epoch= \\\n",
    "            len(train_samples)*3, validation_data=validation_generator, \\\n",
    "            nb_val_samples=len(validation_samples)*3, nb_epoch=25, callbacks= [checkpoint], verbose=1)\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If necessary, we can reduce the learning rate and continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam.lr=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(train_generator, samples_per_epoch= \\\n",
    "            len(train_samples)*3, validation_data=validation_generator, \\\n",
    "            nb_val_samples=len(validation_samples)*3, nb_epoch=50, callbacks= [checkpoint], verbose=1)\n",
    "model.save('model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here is some data exploration. The main goal was to visualize how the distribution was between frames of straight driving and frames of turning.\n",
    "However, I did not remove the straight driving data, since I wanted the neural network to learn from all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "angles = np.asarray([item[3] for item in train_samples]).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max(angles)\n",
    "np.histogram(angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(angles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
